# ğŸ§  LLM API â€“ Multilingual Medical Assistant with RAG

This FastAPI-based application provides a **multilingual conversational assistant for medical queries**, powered by **Gemini Pro (via LangChain)** and a **custom Retrieval-Augmented Generation (RAG)** pipeline using sources like:

- âœ… WHO Fact Sheets  
- âœ… ClinicalTrials.gov  
- âœ… PubMed abstracts  
- âœ… Wikipedia  
- âœ… ArXiv (optional academic support)

It supports **Indian and international languages** like Hindi, Gujarati, Marathi, Tamil, Telugu, French, German, Spanish, and more.

---

## ğŸš€ Features

- ğŸŒ Multilingual language detection & translation
- ğŸ§  Gemini Pro for final response generation
- ğŸ§¾ Integrated data from WHO, PubMed, and ClinicalTrials
- ğŸ“š FAISS-based vector search
- ğŸ§° XML Agent with LangChain tool orchestration
- ğŸ§  Handles follow-ups with conversational memory

---


## ğŸ“ Project Structure

```bash
llm_api/
â”œâ”€â”€ main.py # FastAPI entrypoint
â”œâ”€â”€ rag_engine.py # Core RAG + Gemini logic
â”œâ”€â”€ faiss_store/ # FAISS vector index (auto-generated or preloaded)
â”œâ”€â”€ requirements.txt # All Python dependencies
â””â”€â”€ .env # API keys (not committed)
```
---

## âš™ï¸ Setup Instructions

### 1. Clone the Repository

```bash
git clone https://github.com/22AIML021VishalMehta/LLM_RAG_Component
cd LLM_RAG_Component
```

### 2. Create and Activate Virtual Environment

```bash
python -m venv venv
source venv/bin/activate  # or .\venv\Scripts\activate on Windows
```

### 3. Install Dependencies
```bash
pip install -r requirements.txt
```

### 4. Configure Environment Variables

Create a `.env` file in the root of `LLM_RAG_Component/`:

```bash
GOOGLE_API_KEY=your_gemini_api_key
ENTREZ_API_KEY=your_pubmed_key
ENTREZ_EMAIL=your_email@example.com
USER_AGENT=medbot/1.0 (contact:you@example.com)
```

## â–¶ï¸ Run the Server
```bash
uvicorn main:app --host 0.0.0.0 --port 8000
```
## ğŸ“¡ API Endpoint
POST `/query`

### Request JSON:

```bash
{
  "query": "What are the latest treatments for type 2 diabetes?"
}
```

### Response:
```bash
{
  "query": "What are the latest treatments for type 2 diabetes?",
  "response": "Based on recent medical data...",
  "sources": ["ClinicalTrials.gov", "PubMed"]
}
```

# ğŸ“Œ Notes
- If `faiss_store/` is missing, it will auto-generate the vector index from WHO data.

- Gemini Pro is used via LangChainâ€™s `ChatGoogleGenerativeAI`.

- ClinicalTrials.gov and PubMed content is fetched in real time.

- All queries are translated to English and then back to the userâ€™s language.